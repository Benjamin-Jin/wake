# The internal function operates on imploded strings, not lists
def primjob pool root dir stdin env cmd = prim "job_launch"
def primcache dir stdin env cmd visible = prim "job_cache"

def implode l = cat (foldr (_, "\0", _) Nil l)
def jobcache build dir stdin env cmd visible = memoize 0 (
  match (tryelse (\_ None) (Some _) (primcache dir stdin env.implode cmd.implode visible.implode))
    None     = build 0
    Some out =
      def notOk (Pair name hash) = hashcode name !=* hash
      match (find notOk (tree out 2))
        None = out
        Some (Pair (Pair file saw) _) =
          raise "Hash mismatch for {file} ({saw} != {hashcode file}); remove it or run with -f"
)

# Launch a job, raw interface
# If you use this API, you MUST also run 'finish' on the result AFTER status is available
#   root:  fake root directory
#   dir:   directory where the command should be run
#   stdin: file to attach to standard input ("" = nothing)
#   env:   string list of all environement variables in the form key=value
#   cmd:   string list of command arguments (head is the full path to the command)
def launch root dir stdin env cmd = primjob 1 root dir stdin env.implode cmd.implode

def fail job ok =
  if job.getJobStatus == 0 then ok else raise "Non-zero exit status ({job.getJobStatus})"

# Access the output of a job
def stdio job fd  = prim "job_output" # 1=stdout, 2=stderr; blocks till closed
def tree  job typ = prim "job_tree"   # 0=visible, 1=input, 2=output; blocks till finished
global def killJob job signal = prim "job_kill" # s != 0 => kills; blocks till exit; return status
global def getJobStatus  job = killJob  job 0
global def getJobStdout  job = stdio job 1
global def getJobStderr  job = stdio job 2
global def getJobInputs  job = fail job job.getJobRawInputs
global def getJobOutputs job = fail job job.getJobRawOutputs
global def getJobRawInputs  job = tree job 1 | map first
global def getJobRawOutputs job = tree job 2 | map first
global def getJobOutput = match _.getJobOutputs
  x, Nil = x
  Nil    = raise "no outputs available"
  _      = raise "more than one output found"

# Complete a job, marking done and recording used inputs/outputs
def finish job inputs outputs =
  def imp job inputs outputs = prim "job_finish" # ignored except on first call; blocks till exit; returns true
  imp job inputs.implode outputs.implode

def hashpair f = memoize 0 ( # Pair file hash
  def get f = prim "get_hash"
  def add f h = prim "add_hash"
  def reuse = get f
  if reuse !=* "" then add f reuse else
    def job = launch "." "." "" Nil ("<hash>", f, Nil)
    def final _ = finish job Nil Nil
    def _ = waitOne final job.getJobStatus
    if job.getJobStatus == 0
    then extract '(.{64}).*' job.getJobStdout | head | add f
    else raise "Failed to hash file {f}"
)
def hashname f = hashpair f | first  # just the filename
def hashcode f = hashpair f | second # just the hashcode

# A job where all inputs and outputs are known a-priori
def uncached_manual_job dir stdin env cmd inputs foutputs = memoize 1 (
  def job = launch "." dir stdin env cmd
  def final _ = finish job (map hashname inputs) (map hashname (foutputs Unit))
  def _ = waitOne final job.getJobStatus
  job
)

def cached_manual_job dir stdin env cmd inputs foutputs =
  def build _ = uncached_manual_job dir stdin env cmd inputs foutputs
  jobcache build dir stdin env cmd (map hashname inputs)

# Location of wake itself
def wakepath = prim "execpath"

# Still not caching, just hermetic
def fusepath = relative workspace (simplify "{wakepath}/../lib/wake/fuse-wake")
def uncached_fuse_job dir stdin env cmd files = memoize 0 (
  def visible = dir, map hashname files
  def doit args =
    def fuse = primjob 0 "." "." "" "" args
    def endfuse _ = finish fuse Nil Nil
    def _ = waitOne endfuse fuse.getJobStatus
    def err = fuse.getJobStderr
    def handle _ = raise "Could not start fuse-wake: {err}"
    def list = try handle (extract 'OK: (.*)' err)
    def job = launch list.head dir stdin env cmd
    def final _ = # run once job exits
      def status = killJob fuse 14 # SIGALRM
      def result = extract "(.*\0)?\0(.*)" fuse.getJobStdout
      def inputs  = result | at 0 | tokenize "\0" | reverse | tail
      def outputs = result | at 1 | tokenize "\0" | reverse | tail
      finish job inputs (map hashname outputs)
    def _ = waitOne final job.getJobStatus
    job
  tryelse (raise _.cat) doit (fusepath, visible).implode
)

def cached_fuse_job dir stdin env cmd files =
  def build _ = uncached_fuse_job dir stdin env cmd files
  jobcache build dir stdin env cmd (map hashname files)

data JobOutput =
  FUSE
  Manual (Unit => List String)

# The Job API to get/set/edit jobs
tuple Plan =
  global Command       List String
  global Inputs        List String
  Output JobOutput
  global Environment   List String
  global Directory     String
  global StandardInput String
  global Cache         Boolean

# Most jobs don't need explicit stdin/env control

global def makePlan cmd inputs =
  Plan cmd inputs FUSE environment "." "" True
global def makeManualPlan cmd inputs foutput =
  Plan cmd inputs (Manual foutput) environment "." "" True

# Run the job!
global def makeJob (Plan cmd inputs output env dir stdin cache) = match output cache
  FUSE       True  = cached_fuse_job dir stdin env cmd inputs
  FUSE       False = uncached_fuse_job dir stdin env cmd inputs
  (Manual f) True  = cached_manual_job dir stdin env cmd inputs f
  (Manual f) False = uncached_manual_job dir stdin env cmd inputs f

# Whenever possible, use 'job' if:
#   cmd can run under FUSE
#   cmd guarantees to produce the same outputs given the same inputs
# Examples:
#   gcc
# job only allows cmd access to 'inputs', to prevent undeclared dependencies.
# If you miss declared inputs, your build will fail so you can fix it.
# If you declare too many inputs, cmd execution/replay will wait for unnecessary files.
global def job cmd inputs =
  makePlan cmd inputs
  | makeJob

# Use always_job when:
#   cmd can run under FUSE
#   cmd output can differ between invocations
# Examples:
#   date
# always_job only allows cmd access to 'inputs', to prevent undeclared dependencies.
# If you miss declared inputs, your build will fail so you can fix it.
# If you declare too many inputs, cmd execution/replay will wait for unnecessary files.
global def always_job cmd inputs =
  makePlan cmd inputs
  | setPlanCache False
  | makeJob

# Use manual_job when:
#   cmd cannot run under FUSE, but you know which inputs and outputs cmd uses
#   cmd guarantees to produce the same outputs given the same inputs
# Examples:
#   vcs
# cmd will have access to the entire workspace.
# manual_job behaves like normal target rule in a Makefile.
# If you miss declared inputs, your build is not reproducible and may run in the wrong order.
# If you declare too many inputs, cmd may be rerun and wait unnecessarily.
# If you miss declared outputs, dependant commands might fail or not run reproducibly.
# If you declare too many outputs, the build will fail.
global def manual_job cmd inputs foutputs =
  makeManualPlan cmd inputs foutputs
  | makeJob

# Use volatile_job when:
#   cmd cannot run under FUSE, but you know which inputs and outputs cmd uses
#   cmd output can differ between invocations
# Examples:
#   ???
# volatile_job behaves like a PHONY target in a Makefile.
# If you miss declared inputs, your build is not reproducible and may run in the wrong order.
# If you declare too many inputs, cmd may wait unnecessarily.
# If you miss declared outputs, dependant commands might fail or not run reproducibly.
# If you declare too many outputs, the build will fail.
global def volatile_job cmd inputs foutputs =
  makeManualPlan cmd inputs foutputs
  | setPlanCache False
  | makeJob
